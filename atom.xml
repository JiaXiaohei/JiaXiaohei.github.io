<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>贾小黑的博客</title>
  <subtitle>一只在学习数据分析的Java程序猿</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.jiaxiaohei.com/"/>
  <updated>2017-05-07T06:33:09.283Z</updated>
  <id>http://www.jiaxiaohei.com/</id>
  
  <author>
    <name>贾小黑</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CentOS7下 Hadoop2.7.3+Spark2.1.0 集群环境搭建(1NN+2DN)</title>
    <link href="http://www.jiaxiaohei.com/2017/04/03/CentOS7%E4%B8%8B%20Hadoop2.7.3+Spark2.1.0%20%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(1NN+2DN)/"/>
    <id>http://www.jiaxiaohei.com/2017/04/03/CentOS7下 Hadoop2.7.3+Spark2.1.0 集群环境搭建(1NN+2DN)/</id>
    <published>2017-04-03T13:11:00.000Z</published>
    <updated>2017-05-07T06:33:09.283Z</updated>
    
    <content type="html"><![CDATA[<hr>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><table>
<thead>
<tr>
<th>主机名</th>
<th>ip</th>
<th>进程</th>
</tr>
</thead>
<tbody>
<tr>
<td>nn.hadoop.data.example.net</td>
<td>172.16.156.220</td>
<td>NameNode、Master、ResourceManager、SecondaryNameNode、JobHistoryServer</td>
</tr>
<tr>
<td>dn1.hadoop.data.example.net</td>
<td>172.16.156.221</td>
<td>NodeManager、DataNode、Worker</td>
</tr>
<tr>
<td>dn2.hadoop.data.example.net</td>
<td>172.16.156.222</td>
<td>NodeManager、DataNode、Worker</td>
</tr>
</tbody>
</table>
<p><strong>yum安装如下包 (可能有部分包用不到)</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install pcre-devel openssl openssl-devel openssh-clients htop gcc zlib lrzsz zip unzip vim telnet-server ncurses wget net-tools</div></pre></td></tr></table></figure></p>
<p><strong>关闭防火墙</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">systemctl stop firewalld.service</div><div class="line">systemctl disable firewalld.service</div></pre></td></tr></table></figure></p>
<p><strong>配置hosts文件</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi /etc/hosts</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</div><div class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</div><div class="line"></div><div class="line">172.16.156.220  nn.hadoop.data.example.net</div><div class="line">172.16.156.221  dn1.hadoop.data.example.net</div><div class="line">172.16.156.222  dn2.hadoop.data.example.net</div></pre></td></tr></table></figure>
<h3 id="安装JDK和Scala"><a href="#安装JDK和Scala" class="headerlink" title="安装JDK和Scala"></a>安装JDK和Scala</h3><p><strong>0.创建文件夹</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir /app/java</div><div class="line">mkdir /app/scala</div></pre></td></tr></table></figure></p>
<p><strong>1.下载 </strong><br>下载JDK<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://download.oracle.com/otn-pub/java/jdk/8u121-b13/e9e7ea248e2c4826b92b3f075a80e441/jdk-8u121-linux-x64.tar.gz</div></pre></td></tr></table></figure></p>
<p>如果失效，<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="external">点这里下载</a> 并上传至服务器<br>下载Scala<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://downloads.lightbend.com/scala/2.12.1/scala-2.12.1.tgz</div></pre></td></tr></table></figure></p>
<p><strong>2.移动&amp;解压</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">mv jdk-8u121-linux-x64.tar.gz /app/java</div><div class="line">tar -zxvf jdk-8u121-linux-x64.tar.gz</div><div class="line">mv scala-2.12.1.tgz /app/scala</div><div class="line">tar -zxvf scala-2.12.1.tgz</div></pre></td></tr></table></figure></p>
<p><strong>3.授权</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chmod -R 775 /app/</div><div class="line">chown -R hadoop /app/</div></pre></td></tr></table></figure></p>
<h3 id="创建hadoop用户"><a href="#创建hadoop用户" class="headerlink" title="创建hadoop用户"></a>创建hadoop用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">useradd hadoop</div><div class="line">passwd hadoop</div></pre></td></tr></table></figure>
<p>如无特殊说明 以后均为hadoop用户操作</p>
<h3 id="SSH完密码登录"><a href="#SSH完密码登录" class="headerlink" title="SSH完密码登录"></a>SSH完密码登录</h3><p>生成秘钥：~/.ssh/id_rsa和~/.ssh/id_rsa.pub<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh-keygen -t rsa</div></pre></td></tr></table></figure></p>
<p>拷贝公钥到其他机器上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ssh-copy-id -i nn.hadoop.data.example.net</div><div class="line">ssh-copy-id -i dn1.hadoop.data.example.net</div><div class="line">ssh-copy-id -i dn2.hadoop.data.example.net</div></pre></td></tr></table></figure></p>
<p>###安装Hadoop###<br><strong>0.创建文件夹</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir /app/hadoop/data</div><div class="line">mkdir /app/hadoop/name</div><div class="line">mkdir /app/hadoop/tmp</div></pre></td></tr></table></figure></p>
<p><strong>1.下载hadoop</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz</div></pre></td></tr></table></figure></p>
<p><strong>2.移动&amp;解压</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mv hadoop-2.7.3.tar.gz /app/hadoop</div><div class="line">tar -zxvf hadoop-2.7.3.tar.gz</div></pre></td></tr></table></figure></p>
<p><strong>3.修改配置文件</strong><br><strong>/etc/profile (root权限) </strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">HADOOP_HOME=/app/hadoop/hadoop-2.7.3</div><div class="line">export HADOOP_INSTALL=$HADOOP_HOME</div><div class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</div><div class="line">export YARN_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</div><div class="line">export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</div></pre></td></tr></table></figure></p>
<p><strong>slaves</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">dn1.hadoop.data.example.net</div><div class="line">dn2.hadoop.data.example.net</div></pre></td></tr></table></figure></p>
<p><strong>hadoop-env.sh</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># export JAVA_HOME=$&#123;JAVA_HOME&#125;</div><div class="line">改为</div><div class="line">export JAVA_HOME=/app/java/jdk1.8.0_121/</div></pre></td></tr></table></figure></p>
<p><strong>core-site.xml</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">	&lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">	&lt;value&gt;hdfs://nn.hadoop.data.example.net:9000&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">	&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">	&lt;value&gt;/app/hadoop/tmp&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure></p>
<p><strong>hdfs-site.xml</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">        &lt;value&gt;nn.hadoop.data.example.net:50090&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;/app/hadoop/name&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">        &lt;value&gt;1&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;/app/hadoop/data&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure></p>
<p><strong>mapred-site.xml</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp mapred-site.xml.template mapred-site.xml</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">        &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;nn.hadoop.data.example.net:10020&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;nn.hadoop.data.example.net:19888&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p><strong>yarn-site.xml</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">&lt;!-- Site specific YARN configuration properties --&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</div><div class="line">        &lt;value&gt;nn.hadoop.data.example.net&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">         &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</div><div class="line">         &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure></p>
<p><strong>4.格式化namenode</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop namenode -format</div></pre></td></tr></table></figure></p>
<p><strong>5.复制文件到其他机器</strong><br>将/app/hadoop（包括data、name、tmp和配置好的hadoop）复制到其他机器。<br><strong>6.启动dfs</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">start-dfs.sh</div></pre></td></tr></table></figure></p>
<p><strong>7.启动yarn</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">start-yarn.sh</div></pre></td></tr></table></figure></p>
<p><strong>8.启动jobhistory </strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mr-jobhistory-daemon.sh start historyserver</div></pre></td></tr></table></figure></p>
<p>###安装Spark2###<br><strong>0.创建文件夹</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir /app/spark</div></pre></td></tr></table></figure></p>
<p><strong>1.下载Spark2</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://www.apache.org/dyn/closer.lua/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz</div></pre></td></tr></table></figure></p>
<p><strong>2.移动&amp;解压</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mv spark-2.1.0-bin-hadoop2.7.tgz /app/spark</div><div class="line">tar -zxvf spark-2.1.0-bin-hadoop2.7.tgz</div></pre></td></tr></table></figure></p>
<p><strong>3.修改配置文件</strong><br><strong>/etc/profile (root权限) </strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export SPARK_HOME=/app/spark/spark-2.1.0-bin-hadoop2.7</div><div class="line">export PATH=&quot;$SPARK_HOME/bin:$PATH&quot;</div></pre></td></tr></table></figure></p>
<p><strong>spark-env.sh</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp spark-env.sh.template spark-env.sh</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">export SCALA_HOME=/app/scala/scala-2.12.1</div><div class="line">export JAVA_HOME=/app/java/jdk1.8.0_121</div><div class="line">export SPARK_MASTER_IP=nn.hadoop.data.easydebug.net</div><div class="line">export SPARK_WORKER_MEMORY=1g</div><div class="line">export HADOOP_CONF_DIR=/app/hadoop/hadoop-2.7.3/etc/hadoop</div></pre></td></tr></table></figure>
<p><strong>slaves</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">dn1.hadoop.data.example.net</div><div class="line">dn2.hadoop.data.example.net</div></pre></td></tr></table></figure></p>
<p><strong>4.复制文件到其他机器</strong><br>将/app/spark复制到其他机器。<br><strong>5.启动Spark</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/app/spark/spark-2.1.0-bin-hadoop2.7/sbin/start-all.sh</div></pre></td></tr></table></figure></p>
<p>###安装完成 ^_^###</p>
<hr>
<p><strong> 因为系统变量改了几次 最后贴一下完整的 其实可以在配置前直接贴进去</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/app/java/jdk1.8.0_121</div><div class="line">export SCALA_HOME=/app/scala/scala-2.12.1</div><div class="line">export PATH=$JAVA_HOME/bin:$SCALA_HOME/bin:$PATH</div><div class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</div><div class="line"></div><div class="line">HADOOP_HOME=/app/hadoop/hadoop-2.7.3</div><div class="line">export HADOOP_INSTALL=$HADOOP_HOME</div><div class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</div><div class="line">export YARN_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</div><div class="line">export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</div><div class="line"></div><div class="line">export SPARK_HOME=/app/spark/spark-2.1.0-bin-hadoop2.7</div><div class="line">export PATH=&quot;$SPARK_HOME/bin:$PATH&quot;</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>参考文章</p>
<p>CentOS 6.5 hadoop 2.7.3 集群环境搭建<br><a href="http://blog.csdn.net/mxxlevel/article/details/52653086" target="_blank" rel="external">http://blog.csdn.net/mxxlevel/article/details/52653086</a><br>Spark修炼之道（进阶篇）——Spark入门到精通：第一节 Spark 1.5.0集群搭建<br><a href="https://yq.aliyun.com/articles/60309?spm=5176.8251999.569296.66.0H8Bal" target="_blank" rel="external">https://yq.aliyun.com/articles/60309?spm=5176.8251999.569296.66.0H8Bal</a><br>Hadoop2.7.3+Spark2.1.0 完全分布式环境 搭建全过程<br><a href="http://www.cnblogs.com/purstar/p/6293605.html" target="_blank" rel="external">http://www.cnblogs.com/purstar/p/6293605.html</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      一直想着研究一下Hadoop和Spark开发，记录一下1NN+2DN环境搭建
    
    </summary>
    
      <category term="环境" scheme="http://www.jiaxiaohei.com/categories/%E7%8E%AF%E5%A2%83/"/>
    
    
      <category term="Hadoop" scheme="http://www.jiaxiaohei.com/tags/Hadoop/"/>
    
      <category term="Spark" scheme="http://www.jiaxiaohei.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>facebook开源预测工具Prophet安装方法</title>
    <link href="http://www.jiaxiaohei.com/2017/03/16/facebook%E5%BC%80%E6%BA%90%E9%A2%84%E6%B5%8B%E5%B7%A5%E5%85%B7Prophet%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/"/>
    <id>http://www.jiaxiaohei.com/2017/03/16/facebook开源预测工具Prophet安装方法/</id>
    <published>2017-03-16T15:03:00.000Z</published>
    <updated>2017-05-07T06:29:09.705Z</updated>
    
    <content type="html"><![CDATA[<p>最近研究看到一篇介绍<a href="http://mp.weixin.qq.com/s/6yZRKbH0GYvqHwCDmpL-Uw" target="_blank" rel="external">facebook开源的大规模预测框架Prophet</a>的文章，折腾了两个晚上终于在Win环境下安装成功，把结果分享下。</p>
<hr>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><blockquote>
<ul>
<li>Windows 7 x64  </li>
<li>Anaconda3-4.2.0-Windows-x86 (Python 3.5)</li>
</ul>
</blockquote>
<h3 id="安装Visual-C-2015-Build-Tools"><a href="#安装Visual-C-2015-Build-Tools" class="headerlink" title="安装Visual C++ 2015 Build Tools"></a>安装Visual C++ 2015 Build Tools</h3><blockquote>
<p>Prophet需要C语言编译，在Win环境下需要先安装<a href="http://landinghub.visualstudio.com/visual-cpp-build-tools" target="_blank" rel="external">Visual C++ 2015 Build Tools</a></p>
</blockquote>
<h3 id="安装pystan"><a href="#安装pystan" class="headerlink" title="安装pystan"></a>安装pystan</h3><blockquote>
<p>Prophet依赖pystan包所以也需要安装pystan<br><code>pip install pystan</code></p>
</blockquote>
<h3 id="安装Prophet"><a href="#安装Prophet" class="headerlink" title="安装Prophet"></a>安装Prophet</h3><blockquote>
<p><strong>不要用 pip install fbprophet </strong></p>
<p><a href="https://github.com/facebookincubator/prophet" target="_blank" rel="external">下载</a>prophet最新源码。<br>或者<code>git clone https://github.com/facebookincubator/prophet</code></p>
<p>解压到指定目录，例如D:\Anaconda3\prophet<br>CMD:<br><code>cd D:\Anaconda3\prophet\python</code><br><code>pip install -e .</code></p>
</blockquote>
<h3 id="安装完成"><a href="#安装完成" class="headerlink" title="安装完成"></a>安装完成</h3><hr>
<h3 id="踩过的坑"><a href="#踩过的坑" class="headerlink" title="踩过的坑"></a>踩过的坑</h3><p><strong>1. error: command ‘C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\cl.exe’ failed with exit status 2</strong></p>
<blockquote>
<p>先确认Visual C++ 2015 Build Tools是否安装；如果已经安装，请放弃使用pip安装Prophet。下载源码安装Prophet无问题。</p>
</blockquote>
<p><strong>2. No such file or directory: u’fbprophet/stan_models/linear_growth.pkl</strong></p>
<blockquote>
<p>目测是一个<a href="https://github.com/facebookincubator/prophet/pull/100" target="_blank" rel="external">已知BUG</a> ,已经修复。但好像Release的v0.1源码未更新。直接下载最新源码编译无报错。</p>
</blockquote>
<hr>
<p>###相关文章<br>[1] <a href="http://mp.weixin.qq.com/s/6yZRKbH0GYvqHwCDmpL-Uw" target="_blank" rel="external">http://mp.weixin.qq.com/s/6yZRKbH0GYvqHwCDmpL-Uw</a><br>[2] <a href="http://pystan.readthedocs.io/en/latest/windows.html" target="_blank" rel="external">http://pystan.readthedocs.io/en/latest/windows.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近研究看到一篇介绍&lt;a href=&quot;http://mp.weixin.qq.com/s/6yZRKbH0GYvqHwCDmpL-Uw&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;facebook开源的大规模预测框架Prophet&lt;/a&gt;的文章，折腾了两
    
    </summary>
    
      <category term="数据分析" scheme="http://www.jiaxiaohei.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="http://www.jiaxiaohei.com/tags/Python/"/>
    
      <category term="Prophet" scheme="http://www.jiaxiaohei.com/tags/Prophet/"/>
    
  </entry>
  
</feed>
